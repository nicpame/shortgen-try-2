source_vids_rel_dir = 'data/source_vids' # relative path to source videos directory
source_vid_file_name = 'source_vid.mp4' # name of the source video file
source_audio_file_name = 'source_audio.mp3'
source_thumbnail_file_name = 'source_vid.webp' 
source_metadata_file_name = 'source_vid_metadata.json' 

gened_vids_rel_dir = 'data/gened_vids'
gened_speech_file_name = 'gened_speech.wav'
adjusted_speech_file_name = 'adjusted_speech.wav'
output_video_file_name = 'output_vid.mp4' # name of the output video file
thumbnail_file_name = "thumbnail.png"

raw_transcription_file_name = 'source_transcription.json' # name of the transcription file generated by stt model (api or local)
normalized_transcription_file_name = 'normalized_transcription.json' # name of the normalized transcription file
translate_prompt_file_dir = 'prompts/translate_transcription.md'


# state consts
[video_state]

# source vids prep phase
candidate = "candidate"
downloaded = "downloaded"
audio_extracted = "audio_extracted" # when audio is extracted from the source video
transcription_generated = "transcription_generated"

# gen vids phase
init = 'init' # when gened vid is initialized in db
translated = "translated"
informalized = "informalized" # when translation is modified to be more informal
vocalized = "vocalized" # when translation is vocalized
speech_generated = "speech_generated" # when speech is generated
speech_adjusted = "speech_adjusted" # when speech is adjusted to match video duration
audio_video_mixed = "audio_video_mixed" # when audio and video are mixed
thumbnail_generated = "thumbnail_generated" # when thumbnail is generated
metadata_generated = "metadata_generated" 